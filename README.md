## About
A rag implementation meant to enable "conversation with your voice notes". This project was meant to mainly help blind students who rely on taking notes using specialized computers. These computers are not always available and a sizable percentage of these students lack the required hand coordination to take down notes. So they can instead vocally record their notes and obervations. But listening through hours of these recording just to find a particular topic is a daunting and unnecessary task. My system transcribes a given audio file using Google's Speech-TO-Text model and then tokenizes and stores the text in a Vector Database(FAISS used here). The student could simply ask for a particular topic and this query would be compared with the data in the vector db and the most similar chunks would be extracted. These "chunks" are then structured by an llm (Google's 2 billion parameter Gemma model is used here) and then converted to audio to read out to the user. The advantage of this approach is that not only can the student get responses in the context of their own notes, the llm can further help clear doubts or answer questions that do not match any parts of the trasncribed audio notes.\
This project can also help people who take voice notes as part of their jobs, such as researchers.
\
This idea was developed and built in response to a request from a school for the visually impaired.